{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Input,Conv2D,LeakyReLU,Activation,\n",
    "    Resizing,UpSampling2D,MaxPooling2D,Dropout,Concatenate,Conv2DTranspose\n",
    ")\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import normalize\n",
    "from tensorflow.keras import backend as K\n",
    "# random weight init\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "import tensorflow as tf\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN:\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape,\n",
    "        learning_rate,\n",
    "        lambda_validation,\n",
    "        lambda_reconstr,\n",
    "        lambda_id,\n",
    "        genator_filters,\n",
    "        discriminator_filters,\n",
    "        dataset_path\n",
    "    ):\n",
    "        self.input_shape = input_shape\n",
    "        self.learning_rate = learning_rate \n",
    "        self.lambda_validation = lambda_validation # 指定Lambda验证损失的权重\n",
    "        self.lambda_reconstr = lambda_reconstr # 指定Lambda重构损失的权重\n",
    "        self.lambda_id = lambda_id # 指定Lambda身份损失的权重\n",
    "        self.genator_filters = genator_filters\n",
    "        self.discriminator_filters = discriminator_filters\n",
    "        self.dataset_path = dataset_path\n",
    "        self.channels = self.input_shape[-1]\n",
    "        self.width = self.input_shape[0]\n",
    "        self.height = self.input_shape[1]\n",
    "        self.image_shape = (self.width,self.height,self.channels)\n",
    "        self.patch = int(self.width / 2**4) # 计算PatchGAN中的patch大小\n",
    "        self.disc_patch = (self.patch,self.patch,1) # 计算判别器输出的patch大小\n",
    "        self.epoch = 0\n",
    "        self.load_data()\n",
    "        self.compile_model()\n",
    "    def load_data(self):\n",
    "        self.trainA = tf.keras.utils.image_dataset_from_directory(\n",
    "            os.path.join(self.dataset_path,\"trainA\"),\n",
    "            image_size=(self.width,self.height),\n",
    "            batch_size=1,\n",
    "            label_mode=None,\n",
    "            interpolation=\"bilinear\",\n",
    "            color_mode=\"rgb\"\n",
    "        )\n",
    "        self.trainB = tf.keras.utils.image_dataset_from_directory(\n",
    "            os.path.join(self.dataset_path,\"trainB\"),\n",
    "            image_size=(self.width,self.height),\n",
    "            batch_size=1,\n",
    "            label_mode=None,\n",
    "            interpolation=\"bilinear\",\n",
    "            color_mode=\"rgb\"\n",
    "        )\n",
    "        self.testA = tf.keras.utils.image_dataset_from_directory(\n",
    "            os.path.join(self.dataset_path,\"testA\"),\n",
    "            image_size=(self.width,self.height),    \n",
    "            batch_size=1,\n",
    "            label_mode=None,\n",
    "            interpolation=\"bilinear\",\n",
    "            color_mode=\"rgb\"\n",
    "        )\n",
    "        self.testB = tf.keras.utils.image_dataset_from_directory(\n",
    "            os.path.join(self.dataset_path,\"testB\"),\n",
    "            image_size=(self.width,self.height),\n",
    "            batch_size=1,\n",
    "            label_mode=None,\n",
    "            interpolation=\"bilinear\",\n",
    "            color_mode=\"rgb\"\n",
    "        )\n",
    "        # Normalize images\n",
    "        self.trainA = self.trainA.map(lambda x: x / 255.0)\n",
    "        self.trainB = self.trainB.map(lambda x: x / 255.0)\n",
    "        self.testA = self.testA.map(lambda x: x / 255.0)\n",
    "        self.testB = self.testB.map(lambda x: x / 255.0)\n",
    "        # Convert dataset to numpy array\n",
    "        self.trainA = np.array(list(self.trainA.as_numpy_iterator()))\n",
    "        self.trainB = np.array(list(self.trainB.as_numpy_iterator()))\n",
    "        self.testA = np.array(list(self.testA.as_numpy_iterator()))\n",
    "        self.testB = np.array(list(self.testB.as_numpy_iterator()))\n",
    "        # Reshaping as (None,width,height,channels)\n",
    "        self.trainA = self.trainA.reshape(-1,self.width,self.height,self.channels)\n",
    "        self.trainB = self.trainB.reshape(-1,self.width,self.height,self.channels)\n",
    "        self.testA = self.testA.reshape(-1,self.width,self.height,self.channels)\n",
    "        self.testB = self.testB.reshape(-1,self.width,self.height,self.channels)\n",
    "    def build_generator_unet(self):\n",
    "        def downsample(layer_input, filters, f_size=4):\n",
    "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "            d = InstanceNormalization(axis=-1,center=False,scale=False)(d)\n",
    "            d = Activation('relu')(d)\n",
    "            return d\n",
    "        def upsample(layer_input, skip_input, filters, f_size=4):\n",
    "            u = UpSampling2D(size=2)(layer_input)\n",
    "            u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same')(u)\n",
    "            u = InstanceNormalization(axis=-1,center=False,scale=False)(u) # 使用实例归一化取代批归一化，进一步加强模型的泛化能力\n",
    "            u = Activation('relu')(u)\n",
    "            u = Concatenate()([u, skip_input]) # 跳跃连接，将上采样层的输出与下采样层的输出进行连接\n",
    "            return u\n",
    "        # Image input\n",
    "        img = Input(shape=self.input_shape)\n",
    "        # Downsampling\n",
    "        d1 = downsample(img, self.genator_filters)\n",
    "        d2 = downsample(d1, self.genator_filters*2)\n",
    "        d3 = downsample(d2, self.genator_filters*4)\n",
    "        d4 = downsample(d3, self.genator_filters*8)\n",
    "        # Upsampling\n",
    "        u1 = upsample(d4, d3, self.genator_filters*4)\n",
    "        u2 = upsample(u1, d2, self.genator_filters*2)\n",
    "        u3 = upsample(u2, d1, self.genator_filters)\n",
    "        u4 = UpSampling2D(size=2)(u3)\n",
    "        # Output\n",
    "        # 最后的输出层使用tanh激活函数，将像素值归一化到[-1,1]之间，但输出的维通道仍然与输入的通道相同\n",
    "        output = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u4)\n",
    "        return Model(img, output)\n",
    "    def build_discriminator(self):\n",
    "        # 创建一个4x4的卷积层，步长为2，用于对输入的图像进行下采样\n",
    "        def conv4(layer_input, filters, stride, norm=True):\n",
    "            d = Conv2D(filters, kernel_size=4, strides=stride, padding='same')(layer_input)\n",
    "            if norm:\n",
    "                d = InstanceNormalization(axis=-1,center=False,scale=False)(d)   \n",
    "            d = LeakyReLU(alpha=0.2)(d)\n",
    "            return d\n",
    "        img = Input(shape=self.image_shape)\n",
    "        # 除第一层外，其余层都使用实例归一化\n",
    "        y = conv4(img, self.discriminator_filters, stride=2, norm=False)\n",
    "        y = conv4(y, self.discriminator_filters*2, stride=2)\n",
    "        y = conv4(y, self.discriminator_filters*4, stride=2)\n",
    "        y = conv4(y, self.discriminator_filters*8, stride=1)\n",
    "        # 为了防止与MSE计算时产生张量大小，这里使用了一个8x8的Resize层\n",
    "        # 同时使用双线性插值防止信息丢失\n",
    "        y = Resizing(\n",
    "            8,8,interpolation=\"bilinear\", crop_to_aspect_ratio=False\n",
    "        )(y)\n",
    "        # 最后输出一个8x8x1的PatchGAN输出\n",
    "        output = Conv2D(1, kernel_size=4, strides=1, padding='same')(y)\n",
    "        model = Model(img, output)\n",
    "        return model\n",
    "    def compile_model(self):\n",
    "        # 编译判别器\n",
    "        self.d_A = self.build_discriminator()\n",
    "        self.d_B = self.build_discriminator()\n",
    "        self.d_A.compile(\n",
    "            loss='mse',\n",
    "            optimizer=Adam(self.learning_rate),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        self.d_B.compile(\n",
    "            loss='mse',\n",
    "            optimizer=Adam(self.learning_rate),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        # 编译生成器\n",
    "        self.g_AB = self.build_generator_unet()\n",
    "        self.g_BA = self.build_generator_unet()\n",
    "        # 锁定判别器\n",
    "        self.d_A.trainable = False\n",
    "        self.d_B.trainable = False\n",
    "        # 输入\n",
    "        img_A = Input(shape=self.image_shape)\n",
    "        img_B = Input(shape=self.image_shape)\n",
    "        # 生成器生成\n",
    "        fake_B = self.g_AB(img_A)\n",
    "        fake_A = self.g_BA(img_B)\n",
    "        # 重构\n",
    "        reconstr_A = self.g_BA(fake_B)\n",
    "        reconstr_B = self.g_AB(fake_A)\n",
    "        # 生成器的判别器\n",
    "        valid_A = self.d_A(fake_A)\n",
    "        valid_B = self.d_B(fake_B)\n",
    "        # 生成器的恒等\n",
    "        img_A_id = self.g_BA(img_A)\n",
    "        img_B_id = self.g_AB(img_B)\n",
    "\n",
    "        # 创建混合模型\n",
    "        self.combined = Model(\n",
    "            inputs=[img_A, img_B],\n",
    "            outputs=[valid_A, valid_B, reconstr_A, reconstr_B, img_A_id, img_B_id]\n",
    "        )\n",
    "        self.combined.compile(\n",
    "            loss=['mse', 'mse', 'mae', 'mae', 'mae', 'mae'],\n",
    "            loss_weights=[self.lambda_validation, self.lambda_validation, self.lambda_reconstr\n",
    "                          , self.lambda_reconstr, self.lambda_id, self.lambda_id],\n",
    "            optimizer=Adam(self.learning_rate)\n",
    "        )\n",
    "        # 解锁判别器\n",
    "        self.d_A.trainable = True\n",
    "        self.d_B.trainable = True\n",
    "    def train(self, epochs, batch_size=1):\n",
    "        # 真假标签\n",
    "        valid = np.ones((batch_size,) + self.disc_patch)\n",
    "        fake = np.zeros((batch_size,) + self.disc_patch)\n",
    "        self.disc_loss = []\n",
    "        self.gen_loss = []\n",
    "        self.cycle_loss = []\n",
    "        self.id_loss = []\n",
    "        self.adv_loss = []\n",
    "        with tqdm(total=epochs,unit=\" epoch \") as pbar:\n",
    "            for epoch in range(epochs):\n",
    "                # ----------------------\n",
    "                #  训练判别器\n",
    "                # ----------------------\n",
    "                # 选择一批图片\n",
    "                idx = np.random.randint(0, self.trainA.shape[0], batch_size)\n",
    "                imgs_A = self.trainA[idx]\n",
    "                imgs_B = self.trainB[idx]\n",
    "                # 生成一批假图片\n",
    "                fake_B = self.g_AB.predict(imgs_A)\n",
    "                fake_A = self.g_BA.predict(imgs_B)\n",
    "                # 训练判别器\n",
    "                dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)\n",
    "                dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)\n",
    "                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
    "                dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)\n",
    "                dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)\n",
    "                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
    "                # ------------------\n",
    "                #  训练生成器\n",
    "                # ------------------\n",
    "                # 训练生成器\n",
    "                g_loss = self.combined.train_on_batch([imgs_A, imgs_B], [valid, valid, imgs_A, imgs_B, imgs_A, imgs_B])\n",
    "                # 更新进度条\n",
    "                pbar.set_description(\"Epoch: %d [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f, id: %05f]\" % (\n",
    "                    epoch+1, (dA_loss[0] + dB_loss[0]) / 2, 100 * (dA_loss[1] + dB_loss[1]) / 2, g_loss[0],\n",
    "                    np.mean(g_loss[1:3]), np.mean(g_loss[3:5]), np.mean(g_loss[5:6])))\n",
    "                pbar.update(1)\n",
    "                self.disc_loss.append((dA_loss[0] + dB_loss[0]) / 2)\n",
    "                self.gen_loss.append(g_loss[0])\n",
    "                self.cycle_loss.append(np.mean(g_loss[3:5]))\n",
    "                self.id_loss.append(np.mean(g_loss[5:6]))\n",
    "                self.adv_loss.append(np.mean(g_loss[1:3]))\n",
    "                self.epoch+=1\n",
    "    def sample_image(self):\n",
    "        # 设置Matplotlib渲染三列两行\n",
    "        r, c = 2, 3\n",
    "        # 选择一批图片\n",
    "        idx = np.random.randint(0, self.testA.shape[0], 1)\n",
    "        imgs_A = self.testA[idx] \n",
    "        imgs_B = self.testB[idx] \n",
    "        # 生成图片\n",
    "        fake_B = self.g_AB.predict(imgs_A) \n",
    "        fake_A = self.g_BA.predict(imgs_B) \n",
    "        # 重构图片\n",
    "        reconstr_A = self.g_BA.predict(fake_B) \n",
    "        reconstr_B = self.g_AB.predict(fake_A) \n",
    "        titles = ['Original', 'Translated', 'Reconstructed']\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        # 将图像切换回正常的RGB通道范围\n",
    "        imgs_A = 0.5 * imgs_A + 0.5\n",
    "        imgs_B = 0.5 * imgs_B + 0.5\n",
    "        fake_A = 0.5 * fake_A + 0.5\n",
    "        fake_B = 0.5 * fake_B + 0.5\n",
    "        reconstr_A = 0.5 * reconstr_A + 0.5\n",
    "        reconstr_B = 0.5 * reconstr_B + 0.5\n",
    "        # 绘制图像\n",
    "        axs[0, 0].imshow(imgs_A[0])\n",
    "        axs[0, 0].set_title(titles[0])\n",
    "        axs[0, 1].imshow(fake_B[0])\n",
    "        axs[0, 1].set_title(titles[1])\n",
    "        axs[0, 2].imshow(reconstr_A[0])\n",
    "        axs[0, 2].set_title(titles[2])\n",
    "        axs[1, 0].imshow(imgs_B[0])\n",
    "        axs[1, 1].imshow(fake_A[0])\n",
    "        axs[1, 2].imshow(reconstr_B[0])\n",
    "        fig.show()\n",
    "        plt.show()\n",
    "    def plot_loss(self):\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(\n",
    "            go.Line(\n",
    "                x=list(range(len(self.disc_loss))),\n",
    "                y=self.disc_loss,\n",
    "                name=\"disc_loss\"\n",
    "            )\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Line(\n",
    "                x=list(range(len(self.gen_loss))),\n",
    "                y=self.gen_loss,\n",
    "                name=\"gen_loss\"\n",
    "            )\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Line(\n",
    "                x=list(range(len(self.gen_loss))),\n",
    "                y=self.cycle_loss,\n",
    "                name=\"cycle_loss\"\n",
    "            )\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Line(\n",
    "                x=list(range(len(self.gen_loss))),\n",
    "                y=self.id_loss,\n",
    "                name=\"id_loss\"\n",
    "            )\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Line(\n",
    "                x=list(range(len(self.gen_loss))),\n",
    "                y=self.adv_loss,\n",
    "                name=\"adv_loss\"\n",
    "            )\n",
    "        )\n",
    "        fig.update_layout(\n",
    "            title=\"Training Loss\",\n",
    "            xaxis_title=\"epoch\",\n",
    "            yaxis_title=\"loss\"\n",
    "        )\n",
    "        fig.update_traces(mode=\"markers+lines\")\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型\n",
    "model = CycleGAN(\n",
    "    input_shape=(128, 128, 3),\n",
    "    learning_rate=0.0002,\n",
    "    lambda_validation=1,\n",
    "    lambda_reconstr=10,\n",
    "    lambda_id=2,\n",
    "    genator_filters=32,\n",
    "    discriminator_filters=32,\n",
    "    dataset_path=\"./apple2orange/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "model.train(epochs=1000, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成图片\n",
    "model.sample_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制损失曲线\n",
    "model.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
